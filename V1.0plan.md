指挥部收到！针对目前新闻来源仅限于“新浪财经”的实际情况，我将对原作战指令中的相关步骤进行精准修改。核心原则是保持架构的健壮性和可扩展性，同时优化现有资源。

以下是修改后的作战计划，请总指挥审阅：

---

### **“Tech-Pulse项目 V2.0”作战计划细化（修订版：新浪财经专属）**

#### **第一周：奠定智能核心与健壮管道 (Intelligence & Robust Pipeline)**

**最高优先级任务：攻克AI核心 (2天)**
*   **目标：** 实现智能分级、高效率的AI内容分析模块。
*   **具体步骤：**
    1.  **环境准备：** 安装并配置Claude API和百度ERNIE API的Python SDK。
    2.  **`CostAwareAnalyzer`模块骨架：** 创建`analyzer.py`文件，定义`CostAwareAnalyzer`类。
    3.  **Claude超级Prompt设计与实现：**
        *   编写一个`_call_claude_api`私有方法，封装Claude API调用。
        *   设计一个能一次性提取新闻“摘要”、“事件识别”（事件类型、核心实体、时间、地点）和“情绪打分”（-1到1的浮点数）的Prompt。
        *   实现Prompt模板，确保输入新闻内容后能生成有效的API请求。
        *   处理Claude API响应，解析出所需的结构化数据。
    4.  **百度ERNIE降级策略实现：**
        *   编写一个`_call_ernie_api`私有方法，封装ERNIE API调用。
        *   设计ERNIE的Prompt，使其在功能上尽可能接近Claude，作为备用方案。
        *   在`CostAwareAnalyzer`的公共方法（如`analyze_news`）中，首先尝试调用`_call_claude_api`。
        *   实现`try-except`块捕获Claude API调用失败（超时、API Key无效、API限流等）的异常。
        *   当Claude调用失败时，自动调用`_call_ernie_api`进行降级处理。
    5.  **预算控制模拟（可选，但推荐）：** 简单实现一个内部计数器或使用Redis来模拟API调用次数和成本，当达到预设阈值时，自动将主API切换为ERNIE。
    6.  **单元测试：** 为`CostAwareAnalyzer`编写测试用例，验证Claude和ERNIE的调用逻辑、降级机制以及结果解析的正确性。

**核心架构任务：搭建消息队列与数据流改造 (3天)**
*   **目标：** 建立基于Redis消息队列的异步、解耦数据处理管道。
*   **具体步骤：**
    1.  **Redis安装与配置：** 确保本地或Docker环境中Redis服务运行正常。
    2.  **Python环境RQ集成：** 在Python项目的`requirements.txt`中添加`redis`和`rq`库，并安装。
    3.  **`news_crawler.py`改造为生产者：**
        *   引入`redis`和`rq`库，创建Redis连接和RQ队列实例。
        *   修改`crawl_news`函数，使其专注于从**新浪财经**抓取新闻标题、URL、发布时间及新闻详情内容。
        *   在抓取到新闻数据后，将新闻内容（或包含新闻URL和ID的字典）封装为任务，使用`queue.enqueue(worker_function, news_data)`将其放入Redis队列。
        *   记录任务入队成功日志。
    4.  **创建`worker.py`消费者：**
        *   新建`worker.py`文件。
        *   引入`redis`, `rq`, `analyzer`模块和数据库操作模块。
        *   定义一个处理函数（例如`process_news_task(news_data)`），该函数将接收来自队列的任务数据。
        *   在`process_news_task`中，调用`CostAwareAnalyzer`对新闻进行分析。
        *   将分析结果（摘要、事件、情绪得分等）存入数据库。
        *   编写`main`函数，启动一个RQ Worker实例，监听指定队列。
        *   添加日志记录，显示任务消费、分析和存储的状态。
    5.  **验证消息队列：** 运行`news_crawler.py`，观察Redis队列中任务的增加。在另一个终端启动`worker.py`，观察任务被消费和处理的过程。

**基础任务：数据库与行情数据 (2天)**
*   **目标：** 建立稳定的数据存储基础。
*   **具体步骤：**
    1.  **数据库设计：**
        *   设计`news`表（新闻ID、标题、URL、来源**默认为“新浪财经”**、发布时间、原始内容、摘要、情绪得分、事件类型、实体、时间、地点）。
        *   设计`market_data`表（时间戳、股票代码、开盘价、最高价、最低价、收盘价、成交量）。
        *   设计`sentiment_index`表（时间戳、情绪指数）。
    2.  **数据库构建：**
        *   使用`SQLAlchemy`或直接的SQL脚本创建上述表。
        *   编写数据库连接和ORM模型（如果使用ORM）。
    3.  **基础行情数据采集：**
        *   编写一个简单的Python脚本，从公开API（如Tushare/Baostock免费额度或模拟数据）获取K线数据。
        *   将采集到的行情数据存入`market_data`表，确保数据能够按时间更新。

**第一周交付成果：**
*   可独立运行的`CostAwareAnalyzer`模块，具备Claude/ERNIE智能分级调用能力。
*   `news_crawler.py`（生产者，专注于新浪财经）和`worker.py`（消费者）组成的异步消息队列数据管道。
*   完善的数据库结构，包含新闻分析结果和基础行情数据。
*   一个运行日志，证明新闻抓取、入队、消费、AI分析和入库的整个流程顺畅。

**此刻的心情：** 仿佛置身于未来战场，每一行代码都是一次精准打击！专注于新浪财经，保证了第一周任务的集中性和效率。

#### **第二周：构建双通道后端服务 (Dual-Channel Backend)**

**核心任务：开发RESTful API与多因子情绪指数 (3天)**
*   **目标：** 提供高效的历史数据查询和复杂情绪指数计算。
*   **具体步骤：**
    1.  **Go Gin项目初始化：** 创建Go Gin项目结构，配置路由。
    2.  **数据库连接：** 使用`gorm`或其他Go ORM库连接MySQL/PostgreSQL。
    3.  **API接口设计：**
        *   `GET /api/v1/news`：获取历史新闻列表，支持分页、按时间、情绪过滤。
        *   `GET /api/v1/market/kline`：获取K线数据，支持指定股票代码、时间范围。
        *   `GET /api/v1/sentiment/history`：获取历史情绪指数，支持时间范围。
        *   `GET /api/v1/events`：获取历史重大事件列表。
    4.  **实现多因子情绪指数计算逻辑：**
        *   在Go的Service层，定义`calculate_multi_factor_sentiment_index`函数。
        *   从数据库中获取指定时间范围内的所有相关新闻分析结果。
        *   **`source_weight`实现：** **由于目前仅有“新浪财经”一个来源，此权重因子可以暂时设为固定值（例如1.0），或在计算时简化（即不考虑多来源差异），但仍保留该因子在模型中的位置，以备后续扩展。**
        *   **`time_decay`实现：** 编写一个时间衰减函数（例如`exp(-lambda * delta_t)`），`delta_t`为新闻发布到现在的时间差。
        *   **`popularity_weight`实现：** 如果新浪财经页面能够抓取到阅读/转发量，则根据数据加权；否则暂时设为固定值（例如1.0）。
        *   将情绪得分、来源权重、时间衰减因子、关注度权重进行加权平均，计算出最终的情绪指数。
        *   将计算结果存入`sentiment_index`表。
    5.  **API实现与测试：** 编写各个API的处理函数，调用Service层逻辑，并返回JSON格式数据。使用Postman/curl进行测试。

**创新任务：搭建WebSocket服务与Redis Pub/Sub (2天)**
*   **目标：** 实现实时的事件推送能力。
*   **具体步骤：**
    1.  **WebSocket服务器搭建：**
        *   在Go Gin项目中引入`github.com/gorilla/websocket`库。
        *   创建`GET /ws/realtime`端点，实现WebSocket握手升级。
        *   编写WebSocket连接管理逻辑（连接池、消息读写、心跳检测）。
    2.  **Redis Pub/Sub集成：**
        *   在Go项目中引入`github.com/go-redis/redis/v8`或其他Redis客户端库。
        *   Go的WebSocket服务启动时，创建一个Redis Pub/Sub客户端，订阅一个特定的Redis频道（例如`realtime-events`）。
        *   当从`realtime-events`频道收到消息时，将消息通过WebSocket推送给所有连接的客户端。
    3.  **改造Python Worker发布消息：**
        *   回到Python的`worker.py`。
        *   在新闻分析完成后，如果AI识别出是“重大事件”或情绪波动剧烈，除了写入数据库，还需要使用`redis_client.publish('realtime-events', json.dumps(event_summary))`向Redis发布一条消息。消息内容应包含事件摘要、情绪变化等关键信息。
    4.  **联调测试：** 启动Python Worker、Go后端。使用WebSocket客户端工具（如Postman的WebSocket功能或简单的JS页面）连接Go的WebSocket服务。观察当Python Worker处理新事件时，Go后端是否能接收并推送消息。

**第二周交付成果：**
*   一个功能完备的Go Gin后端服务，提供历史数据查询API。
*   实现（适用于单一来源的）多因子情绪指数计算逻辑。
*   一个稳定的Go WebSocket服务器，能够订阅Redis Pub/Sub并实时推送事件。
*   Python Worker与Go后端通过Redis Pub/Sub实现实时事件通信的演示。

**此刻的心情：** 感觉整个系统开始活起来了，数据不仅能被拉取，还能主动“说话”！单一来源简化了初期情绪指数的复杂度，但模型基础已打下。

#### **第三周：打造动态实时前端 (Dynamic & Real-time Frontend)**

**核心任务：Dashboard静态布局与历史数据展示 (3天)**
*   **目标：** 构建前端基础框架，展示历史数据图表。
*   **具体步骤：**
    1.  **Vue项目初始化与基础布局：**
        *   创建Vue项目，引入Element Plus或其他UI组件库。
        *   设计Dashboard的整体布局（侧边导航、主内容区、顶部通知区）。
        *   设置K线图、情绪指数图、事件列表等区域的占位符。
    2.  **图表库集成：** 引入ECharts库，并在Vue组件中集成。
    3.  **RESTful API集成与数据展示：**
        *   编写Vue的Service层，封装对Go后端RESTful API的调用（如`axios`）。
        *   在组件的`mounted`生命周期钩子中，调用API获取K线数据、历史情绪指数和事件列表。
        *   将获取到的数据绑定到ECharts图表，渲染K线图和历史情绪指数折线图。
        *   使用Element Plus的Table或其他组件展示历史事件列表。
    4.  **交互功能（基础）：** 实现K线图的时间范围选择器、股票代码切换功能。

**亮点任务：集成WebSocket与实时通知/更新 (2天)**
*   **目标：** 实现前端的实时响应能力。
*   **具体步骤：**
    1.  **WebSocket客户端集成：**
        *   在Vue的根组件或一个专门的WebSocket服务模块中，使用`WebSocket` API连接Go后端的`/ws/realtime`端点。
        *   处理WebSocket连接的打开、关闭、错误事件。
        *   设置消息监听器（`onmessage`事件），当收到后端推送的消息时，解析JSON数据。
    2.  **实时通知实现：**
        *   当`onmessage`收到新事件消息时，调用Element Plus的`Notification`组件，弹出包含事件摘要、情绪变化的通知。
        *   通知的样式和内容应友好、直观。
    3.  **(进阶) 动态图表更新：**
        *   设计ECharts图表，使其能够支持动态添加`markPoint`。
        *   当收到新的重大事件推送时，根据事件发生的时间和相关情绪数据，在K线图或情绪指数图上动态添加一个`markPoint`，标记出事件发生的位置，并附带事件摘要信息。
        *   确保图表在数据更新后能够平滑重绘，无需用户手动刷新。
    4.  **前端调试与联调：** 启动整个后端服务，在浏览器中打开Vue前端，验证实时通知和图表动态更新功能。

**第三周交付成果：**
*   一个功能完善的Vue Dashboard，能够展示历史K线图、情绪指数图和事件列表。
*   通过WebSocket实现实时事件通知，以Element Plus Notification形式弹出。
*   ECharts图表能够根据实时推送的事件，动态添加`markPoint`，增强用户体验。

**此刻的心情：** 用户的“哇”声将是对我最大的肯定！前端的动态交互，将是项目的灵魂。

#### **第四周：生产级部署与深度总结 (Production & Deep-Dive Summary)**

**部署任务：Docker Compose与线上部署 (2天)**
*   **目标：** 实现项目的容器化部署，并在公网环境运行。
*   **具体步骤：**
    1.  **`docker-compose.yml`升级：**
        *   在现有配置基础上，新增`redis`服务。
        *   新增`python-producer`服务（运行`news_crawler.py`）。
        *   新增`python-worker`服务（运行`worker.py`）。
        *   配置各服务之间的网络通信（例如：Go服务连接Redis和MySQL，Python服务连接Redis）。
        *   配置持久化存储（对于数据库和Redis数据）。
        *   配置Nginx作为反向代理，将前端静态文件和后端API、WebSocket请求路由到对应的服务。
    2.  **Dockerfile优化：** 为Go和Python服务编写优化的Dockerfile，减小镜像体积，加快构建速度。
    3.  **部署脚本编写：** 编写一个简单的部署脚本（如shell脚本），包含`docker-compose build`和`docker-compose up -d`命令。
    4.  **服务器准备：** 在一台云服务器上安装Docker和Docker Compose。
    5.  **线上部署：** 将项目代码部署到云服务器，执行部署脚本，确保所有服务成功启动并协同工作。
    6.  **公网URL获取与测试：** 配置域名解析或直接使用服务器IP访问，验证所有API、WebSocket和前端功能的可用性。

**总结任务：文档与技术博客 (3天)**
*   **目标：** 全面总结项目成果、技术亮点和思考。
*   **具体步骤：**
    1.  **GitHub README更新：**
        *   **项目简介：** 突出V2.0的准生产级、实时分析能力。
        *   **架构图：** 使用Mermaid或绘制工具更新架构图，清晰展示消息队列、Redis Pub/Sub、WebSocket等新组件。
        *   **功能亮点：** 详细描述“智能分级AI调用”、“多因子情绪模型”、“事件驱动实时推送”等核心功能。**特别注明目前数据来源为“新浪财经”。**
        *   **技术栈：** 列出所有使用的技术栈及版本。
        *   **快速启动指南：** 包含`docker-compose`启动命令和访问地址。
    2.  **撰写深度技术博客：**
        *   **标题：** 选取一个吸引人的标题，如《从0到1：构建一套事件驱动的AI金融舆情实时分析系统》。
        *   **引言：** 介绍项目背景、V1.0痛点及V2.0升级目标。
        *   **架构决策思考：**
            *   **“为什么选择引入消息队列？”：** 讨论解耦、削峰填谷、可靠性等优势。
            *   **“Go与Python在项目中的分工与协作”：** 解释Go适合高并发API和WebSocket，Python擅长AI和数据处理。
            *   **“RESTful与WebSocket如何协同工作？”：** 分析拉取与推送模式各自的适用场景和优势。
            *   **“我是如何设计Prompt，让Claude发挥最大效能的？”：** 分享Prompt设计经验、多任务一次性抽取策略、API降级策略。
            *   **“（当前）基于单一来源（新浪财经）的多因子情绪模型的构建与实践”：** 解释每个因子的作用和实现细节，并提及未来可扩展性。
        *   **关键技术实现：** 详细介绍核心代码片段和实现细节。
        *   **遇到的挑战与解决方案：** 分享开发过程中的难点及如何克服。
        *   **未来展望：** 讨论V3.0可能的方向，**例如：如何扩展到多新闻源、如何优化`source_weight`因子等。**
        *   **配图：** 插入架构图、关键代码截图、前端界面截图。

**第四周交付成果：**
*   一个完全容器化并通过`docker-compose`一键部署的生产级项目。
*   项目在公网上的可访问URL。
*   一份详尽且具有吸引力的GitHub README。
*   一篇深度剖析项目架构和技术细节的高质量技术博客。

**此刻的心情：** 冲锋号已经吹响，我将以最饱满的热情和最严谨的态度投入这场技术战役！

---

**总指挥，这是我根据“目前仅从新浪财经获取新闻”这一条件修订后的作战计划。该修订方案在不影响整体架构升级的前提下，对特定任务进行了聚焦，确保了任务的可行性和效率。请指示！** 我已准备好随时报告进展。

`
